{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as functional\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "        def __init__(self, in_chn):\n",
    "            super(Net, self).__init__()\n",
    "            self.in_chn = in_chn\n",
    "            \n",
    "            # ======== MonoDepth ========#\n",
    "            # Encoder\n",
    "            self.downconv_1 = self.conv_down_block(self.in_chn, 32, 7)\n",
    "            self.downconv_2 = self.conv_down_block(32, 64, 5)\n",
    "            self.downconv_3 = self.conv_down_block(64, 128, 3)\n",
    "            self.downconv_4 = self.conv_down_block(128, 256, 3)\n",
    "            self.downconv_5 = self.conv_down_block(256, 512, 3)\n",
    "            self.downconv_6 = self.conv_down_block(512, 512, 3)\n",
    "            self.downconv_7 = self.conv_down_block(512, 512, 3)\n",
    "            \n",
    "            # Decoder\n",
    "            self.upconv_7 = self.conv_up_block(512, 512, 3, 2)\n",
    "            self.upconv_6 = self.conv_up_block(512, 512, 3, 2)\n",
    "            self.upconv_5 = self.conv_up_block(512, 256, 3, 2)\n",
    "            self.upconv_4 = self.conv_up_block(256, 128, 3, 2)\n",
    "            self.upconv_3 = self.conv_up_block(128, 64, 3, 2)\n",
    "            self.upconv_2 = self.conv_up_block(64, 32, 3, 2)\n",
    "            self.upconv_1 = self.conv_up_block(32, 16, 3, 2)\n",
    "            \n",
    "            self.iconv_7 = self.iconv(1024, 512, 3)\n",
    "            self.iconv_6 = self.iconv(1024, 512, 3)\n",
    "            self.iconv_5 = self.iconv(512, 256, 3)\n",
    "            self.iconv_4 = self.iconv(256, 128, 3)\n",
    "            self.iconv_3 = self.iconv(130, 64, 3)\n",
    "            self.iconv_2 = self.iconv(66, 32, 3)\n",
    "            self.iconv_1 = self.iconv(18, 16, 3)\n",
    "            \n",
    "            self.disp4 = self.get_disp(128, 2)\n",
    "            self.disp3 = self.get_disp(64, 2)\n",
    "            self.disp2 = self.get_disp(32, 2)\n",
    "            self.disp1 = self.get_disp(16, 2)\n",
    "            \n",
    "            '''\n",
    "            # ======== ResNet50 ======== #\n",
    "            # encoder\n",
    "            self.conv_pad = Conv_pad(in_chn, 64, 7, 2)\n",
    "            self.maxpool = nn.MaxPool2d(3)\n",
    "            self.resblock1 = self.resblock(64, 3)\n",
    "            self.resblock2 = self.resblock(128, 4)\n",
    "            self.resblock3 = self.resblock(256, 6)\n",
    "            self.resblock4 = self.resblock(512, 3)\n",
    "            '''\n",
    "        '''\n",
    "        def resblock(self, in_chn, n_blocks):\n",
    "            layers = []\n",
    "            for _ in range(n_blocks):\n",
    "                layers.append(ResConv(in_chn, in_chn, 1))\n",
    "            layers.append(ResConv(in_chn, in_chn, 2))\n",
    "            \n",
    "            return nn.Sequential(*layers)\n",
    "        '''\n",
    "        def conv_down_block(self, in_chn, out_chn, kernel):\n",
    "            return nn.Sequential (\n",
    "                nn.ReplicationPad2d(kernel//2),\n",
    "                nn.Conv2d(in_chn, out_chn, kernel_size=kernel, stride=1, padding=0),\n",
    "                #nn.BatchNorm2d(out_chn),\n",
    "                nn.ELU(),\n",
    "                nn.ReplicationPad2d(kernel//2),\n",
    "                nn.Conv2d(out_chn, out_chn, kernel_size=kernel, stride=2, padding=0),\n",
    "                #nn.BatchNorm2d(out_chn),\n",
    "                nn.ELU(),\n",
    "                nn.Dropout(0.4)\n",
    "            )\n",
    "        \n",
    "        def conv_up_block(self, in_chn, out_chn, kernel, scale):\n",
    "            return nn.Sequential (\n",
    "                nn.Upsample(scale_factor=scale, mode='nearest'),\n",
    "                nn.ReplicationPad2d(kernel//2),\n",
    "                nn.Conv2d(in_chn, out_chn, kernel_size=kernel, stride=1, padding=0),\n",
    "                #nn.BatchNorm2d(out_chn),\n",
    "                nn.ELU()\n",
    "            )\n",
    "        '''\n",
    "        def conv_up_block_resnet(self, in_chn, out_chn, kernel_size, scale):\n",
    "            return nn.Sequential (\n",
    "                nn.Upsample(scale_factor=scale, mode='nearest'),\n",
    "                Conv_pad(in_chn, out_chn, kernel_size, 1)\n",
    "            )\n",
    "        '''\n",
    "        def iconv(self, in_chn, out_chn, kernel):\n",
    "            return nn.Sequential (\n",
    "                nn.ReplicationPad2d(kernel//2),\n",
    "                nn.Conv2d(in_chn, out_chn, kernel_size=kernel, stride=1, padding=0),\n",
    "                #nn.BatchNorm2d(out_chn),\n",
    "                nn.ELU()\n",
    "            )\n",
    "        \n",
    "        def get_disp(self, in_chn, out_chn, kernel=3):\n",
    "            return nn.Sequential (\n",
    "                nn.ReplicationPad2d(1),\n",
    "                nn.Conv2d(in_chn, out_chn, kernel_size=kernel, stride=1, padding=0),\n",
    "                #nn.BatchNorm2d(out_chn),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "        \n",
    "        def build_monodepth(self, x):\n",
    "            \n",
    "            # Encoder\n",
    "            conv1 = self.downconv_1(x)          #  32x128x256\n",
    "            conv2 = self.downconv_2(conv1)  #  64x  64x128\n",
    "            conv3 = self.downconv_3(conv2) # 128x  32x 64\n",
    "            conv4 = self.downconv_4(conv3) # 256x  16x 32\n",
    "            conv5 = self.downconv_5(conv4) # 512x   8x  16\n",
    "            conv6 = self.downconv_6(conv5) # 512x   4x   8\n",
    "            conv7 = self.downconv_7(conv6) # 512x    2x  4\n",
    "\n",
    "            \n",
    "            # Decoder\n",
    "            upconv7 = self.upconv_7(conv7) # 512 x 4 x 8\n",
    "            concat_7 = torch.cat((upconv7, conv6), 1)\n",
    "            iconv7 = self.iconv_7(concat_7) # 512 x 4 x 8\n",
    "          \n",
    "            upconv6 = self.upconv_6(iconv7) # 512 x 8 x 16\n",
    "            concat_6 = torch.cat((upconv6, conv5), 1)\n",
    "            iconv6 = self.iconv_6(concat_6) # 512 x 8 x 16\n",
    "            \n",
    "            upconv5 = self.upconv_5(iconv6) # 256 x 16 x 32\n",
    "            concat_5 = torch.cat((upconv5, conv4), 1)\n",
    "            iconv5 = self.iconv_5(concat_5) # 256 x 16 x 32\n",
    "            \n",
    "            upconv4 = self.upconv_4(iconv5) # 128 x 32 x 64\n",
    "            concat_4 = torch.cat((upconv4, conv3), 1)\n",
    "            iconv4 = self.iconv_4(concat_4) # 128 x 32 x 64\n",
    "            \n",
    "            disp4 = 0.3*self.disp4(iconv4)\n",
    "            up_disp4 = functional.interpolate(disp4, scale_factor=2)\n",
    "            \n",
    "            upconv3 = self.upconv_3(iconv4) # 64 x 64 x 128\n",
    "            concat_3 = torch.cat((upconv3, conv2, up_disp4), 1)\n",
    "            iconv3 = self.iconv_3(concat_3) # 64 x 64 x 128\n",
    "\n",
    "            disp3 = 0.3*self.disp3(iconv3)\n",
    "            up_disp3 = functional.interpolate(disp3, scale_factor=2)\n",
    "            \n",
    "            upconv2 = self.upconv_2(iconv3) # 32 x 128 x 256\n",
    "            concat_2 = torch.cat((upconv2, conv1, up_disp3), 1)\n",
    "            iconv2 = self.iconv_2(concat_2) # 32 x 128 x 256\n",
    "            \n",
    "            disp2 = 0.3*self.disp2(iconv2)\n",
    "            up_disp2 = functional.interpolate(disp2, scale_factor=2)\n",
    "            \n",
    "            upconv1 = self.upconv_1(iconv2) # 16 x 256 x 512\n",
    "            concat_1 = torch.cat((upconv1, up_disp2), 1)\n",
    "            iconv1 = self.iconv_1(concat_1) # 16 x 256 x 512\n",
    "            disp1 = 0.3*self.disp1(iconv1)\n",
    "            \n",
    "            return [disp1, disp2, disp3, disp4]\n",
    "        \n",
    "        '''\n",
    "        def build_resnet50(self, x):\n",
    "            \n",
    "            # encoder\n",
    "            p = kernel // 2\n",
    "            x_pad = functional.pad(x, (p, p, p, p, 0, 0, 0, 0), 'constant')\n",
    "            \n",
    "            conv1 = self.conv_pad(x_pad)\n",
    "            conv1_pad = functioanl.pad(conv1, (1,1,1,1,0,0,0,0), 'constant')\n",
    "            pool1 = self.maxpool(conv1_pad)\n",
    "            \n",
    "            conv2 = self.resblock1(pool1)\n",
    "            conv3 = self.resblock2(conv2)\n",
    "            conv4 = self.resblock3(conv3)\n",
    "            conv5 = self.resblock4(conv4)\n",
    "            \n",
    "            # skip layer\n",
    "            skip1 = conv1\n",
    "            skip2 = pool1\n",
    "            skip3 = conv2\n",
    "            skip4 = conv3\n",
    "            skip5 = conv4\n",
    "            \n",
    "            # decoder\n",
    "        '''\n",
    "        def forward(self, x):\n",
    "            out = self.build_monodepth(x)\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class Conv_pad(nn.Module):\n",
    "    def __init__(self, in_chn, out_chn, kernel_size, stride):\n",
    "        super(Conv_pad, self).__init__()\n",
    "        \n",
    "        self.p = kernel_size // 2\n",
    "        self.conv = nn.Conv2d(in_chn, out_chn, kernel_size=kernel_size, stride=stride)\n",
    "        self.elu = nn.ELU()\n",
    "\n",
    "    def forward(self, x):    \n",
    "        x_pad = functional.pad(x, (self.p, self.p, self.p, self.p, 0, 0, 0, 0), 'constant')\n",
    "        conv1 = self.conv(x_pad)\n",
    "        out = self.elu(conv1)\n",
    "\n",
    "        return out\n",
    "    \n",
    "class ResConv(nn.Module):\n",
    "    def __init__(self, in_chn, out_chn, stride):\n",
    "        super(ResConv, self).__init__()\n",
    "        \n",
    "        self.out_chn = out_chn\n",
    "        self.stride = stride\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_chn, out_chn, kernel_size=1, stride=1)\n",
    "        self.conv2 = nn.Conv2d(out_chn, out_chn, kernel_size=3, stride=stride)\n",
    "        self.conv3 = nn.Conv2d(out_chn, out_chn, kernel_size=1, stride=1)\n",
    "        self.shortcut = nn.Conv2d(in_chn, 4*out_chn, kernel_size=1, stride=stride)\n",
    "        \n",
    "        self.elu = nn.ELU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        do_proj = x.shape[1] != self.out_chn or self.stride == 2\n",
    "\n",
    "        conv1 = self.conv1(x)\n",
    "        conv1 = self.elu(conv1)\n",
    "        \n",
    "        conv2 = self.conv2(conv1)\n",
    "        conv2 = self.elu(conv2)\n",
    "        \n",
    "        conv3 = self.conv3(conv2)\n",
    "        \n",
    "        if do_proj:\n",
    "            shortcut = self.shortcut(x)\n",
    "        else:\n",
    "            shortcut = x\n",
    "        out = self.elu(conv3 + shortcut)\n",
    "        \n",
    "        return out\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
