{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable, grad\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from tensorboardX import SummaryWriter\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import config\n",
    "from depthmodel import DepthModel\n",
    "import utils\n",
    "from glob import glob\n",
    "from dataloader import Dataloader as DL\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mat\n",
    "mat.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def post_process_disparity(disp, disp_flip):\n",
    "    h, w = disp.shape\n",
    "    #l_disp = disp[0,:,:]\n",
    "    #r_disp = np.fliplr(disp[1,:,:])\n",
    "    l_disp = disp\n",
    "    r_disp = disp_flip\n",
    "    m_disp = 0.5 * (l_disp + r_disp)\n",
    "    l, _ = np.meshgrid(np.linspace(0, 1, w), np.linspace(0, 1, h))\n",
    "    l_mask = 1.0 - np.clip(20 * (l - 0.05), 0, 1)\n",
    "    r_mask = np.fliplr(l_mask)\n",
    "    return r_mask * l_disp + l_mask * r_disp + (1.0 - l_mask - r_mask) * m_disp\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # network model and parameters\n",
    "    params, _ = config.get_config()\n",
    "    model = DepthModel(params)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        # GPU setting\n",
    "        print(\"GPU Acceleration Available\")\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "        model.set_cuda()\n",
    "        \n",
    "    if params.mode == 'train':\n",
    "        # loading training data and validation data\n",
    "        data_loader_train= DL(params, 'train', sys.argv[1])\n",
    "        train_data = DataLoader(data_loader_train, batch_size=params.batch_size, shuffle=True)  \n",
    "        data_loader_valid = DL(params, 'valid', sys.argv[1])\n",
    "        valid_data = DataLoader(data_loader_valid, batch_size=params.batch_size, shuffle=False)\n",
    "        \n",
    "        # optimizer\n",
    "        opt = torch.optim.Adam(model.G.parameters(), lr=params.learning_rate)\n",
    "        \n",
    "        # tensorboard visualization\n",
    "        writer = SummaryWriter('runs/{}'.format(params.model_type), comment='epoch{}_lr{}'.format(params.epoch, params.learning_rate))\n",
    "        \n",
    "        # resume training\n",
    "        if params.resume:\n",
    "            checkpoint = torch.load(os.path.join('checkpoints', params.model_type, params.resume), map_location=lambda storage, loc: storage)\n",
    "            print ('=> loading checkpoint {}/{}, last training loss = {:.5f}'.format(params.model_type, params.resume, checkpoint['loss']))\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            model.G.load_state_dict(checkpoint['model_state_dict'])\n",
    "            opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            scheduler = MultiStepLR(opt, milestones=[int(params.epoch*(1/2)), int(params.epoch*(4/5))], gamma=0.5, last_epoch=start_epoch)\n",
    "        else:\n",
    "            start_epoch = 0\n",
    "            scheduler = MultiStepLR(opt, milestones=[int(params.epoch*(1/2)), int(params.epoch*(4/5))], gamma=0.5, last_epoch=-1)\n",
    "\n",
    "        # start training\n",
    "        for epoch in range(start_epoch+1, params.epoch+1):\n",
    "            \n",
    "            epoch_start_time = time.time()\n",
    "            scheduler.step()\n",
    "            print ('{} epoch starts, learning rate = {}'.format(epoch, utils.get_lr(opt)))\n",
    "            \n",
    "            for i, data in enumerate(train_data):\n",
    "                iter_start_time = time.time()\n",
    "                loss = model.forward(data['left_image'], data['right_image'])\n",
    "                opt.zero_grad()\n",
    "                model.total_loss.backward()\n",
    "                opt.step()    \n",
    "\n",
    "                if i % 200 == 0:\n",
    "                    iter_duration = time.time() - iter_start_time\n",
    "                    print ('epoch {:2d} | iteration {:4d} | loss = {:.3f} (img={:.3f}, disp={:.5f}, consist={:3f}) | {:.2f} sec' \\\n",
    "                                .format(epoch, i, loss, model.image_loss.item(), model.disp_gradient_loss.item(), model.lr_loss.item(), iter_duration))\n",
    "           \n",
    "            # save checkpoints at checkpoints/<model name>/cp_epoch<n>_lr<n>.pth\n",
    "            if not os.path.exists('checkpoints/{}'.format(params.model_type)):\n",
    "                os.makedirs('checkpoints/{}'.format(params.model_type))\n",
    "            time.sleep(8)\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.G.cpu().state_dict(),\n",
    "                'optimizer_state_dict': opt.state_dict(),\n",
    "                'loss': loss\n",
    "            }, 'checkpoints/{}/cp_epoch{:02d}.pth'.format(params.model_type, epoch))\n",
    "            model.G = model.G.cuda()\n",
    "            \n",
    "            # validation and display the images\n",
    "            for d in valid_data:\n",
    "                loss_v = model.forward(d['left_image'], d['right_image'])\n",
    "                model.display_image('img/{}'.format(params.model_type), epoch)\n",
    "                break\n",
    "            \n",
    "            # plot the loss chart in tensorboard\n",
    "            writer.add_scalars('train_loss', {\n",
    "                            'image loss': model.image_loss.item(), \n",
    "                            'Disparity smoothness': params.disp_gradient_loss_weight * model.disp_gradient_loss.item(),\n",
    "                            'Consistency': params.lr_loss_weight * model.lr_loss.item()}, epoch)\n",
    "            writer.add_scalars('train_valid_loss', {\n",
    "                            'train loss': loss,\n",
    "                            'valid loss': loss_v}, epoch)\n",
    "            \n",
    "            epoch_duration = time.time() - epoch_start_time\n",
    "            print ('epoch {} spending time = {:.2f} sec\\n'.format(epoch, epoch_duration))\n",
    "            \n",
    "        writer.close()\n",
    "        \n",
    "    elif params.mode == 'test' or params.mode == 'evaluate':\n",
    "        \n",
    "        # load testing dataset\n",
    "        data_loader_test = DL(params, params.mode, sys.argv[1])\n",
    "        test_data = DataLoader(data_loader_test, batch_size=params.batch_size, shuffle=False)\n",
    "        \n",
    "        # load trained model. Here we find the last epoch's checkpoint and load it\n",
    "        cp_list = glob('checkpoints/{}/cp_epoch*.pth'.format(params.model_type))\n",
    "        cp_filename = max(cp_list, key=lambda f: int(re.findall('\\d+', f)[0]))\n",
    "        print ('=> loading model {}'.format(cp_filename))\n",
    "        cp = torch.load(cp_filename)\n",
    "        model.G.load_state_dict(cp['model_state_dict'])\n",
    "        \n",
    "        disparities = np.zeros((len(test_data)*params.batch_size, params.height, params.width), dtype=np.float32)\n",
    "        disparities_pp = np.zeros((len(test_data)*params.batch_size, params.height, params.width), dtype=np.float32)\n",
    "        \n",
    "        print ('Start testing {} samples...'.format(len(test_data)*params.batch_size))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(test_data):\n",
    "                model.forward(data['left_image'], data['right_image'])\n",
    "                disp = model.disp_est[0]\n",
    "                model.forward(torch.flip(data['left_image'], [3]), torch.flip(data['right_image'], [3]))\n",
    "                disp_flip = model.disp_est[0]\n",
    "                \n",
    "                for j in range(params.batch_size):\n",
    "                    \n",
    "                    # disparity map\n",
    "                    disp_np = disp[j,0,:,:].squeeze().cpu().numpy()\n",
    "                    disparities[i*params.batch_size+j] = disp_np\n",
    "                    '''\n",
    "                    plt.figure()\n",
    "                    plt.imshow(disp_np, cmap=plt.get_cmap('plasma'))\n",
    "                    plt.axis('off')\n",
    "                    plt.savefig('evaluation/img/{}/{:03d}.png'.format(params.model_type, i*params.batch_size + j))\n",
    "                    plt.close()\n",
    "                    '''\n",
    "                    \n",
    "                    # disparity map with post-processing\n",
    "                    #disp_np_pp = disp[j].squeeze().cpu().data.numpy()\n",
    "                    disp_np_pp = disp[j,0,:,:].squeeze().cpu().data.numpy()\n",
    "                    disp_flip_np_pp = disp_flip[j,0,:,:].squeeze().cpu().data.numpy()\n",
    "                    disparities_pp[i*params.batch_size+j] = post_process_disparity(disp_np_pp, disp_flip_np_pp[:,::-1])\n",
    "                    '''\n",
    "                    plt.figure()\n",
    "                    plt.imshow(disp_np_pp, cmap=plt.get_cmap('plasma'))\n",
    "                    plt.axis('off')\n",
    "                    plt.savefig('evaluation/img/{}/{:03d}_pp.png'.format(params.model_type, i*params.batch_size + j))\n",
    "                    plt.close()\n",
    "                    '''\n",
    "                    \n",
    "        if not os.path.exists(params.output_directory):\n",
    "            os.makedirs(params.output_directory)\n",
    "        np.save('{}/npy/disparities_{}.npy'.format(params.output_directory, params.model_type), disparities)\n",
    "        np.save('{}/npy/disparities_{}_pp.npy'.format(params.output_directory, params.model_type), disparities_pp)\n",
    "        \n",
    "        print ('Finished testing. Saved the output file at {}/npy/disparities_{}.npy'.format(params.output_directory, params.model_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
