{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as functional\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import model_monodepth\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mat\n",
    "mat.use('Agg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepthModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, params):\n",
    "        super(DepthModel, self).__init__()\n",
    "        \n",
    "        self.params = params\n",
    "        \n",
    "        # The encoder-decoder model. It can be monodepth-model, ResNet-50\n",
    "        if self.params.model_type.find('mono_depth') >= 0:\n",
    "            from model_monodepth import Net\n",
    "            self.G = Net(self.params.channel)\n",
    "        elif self.params.model_type == 'resnet50':\n",
    "            import model_resnet\n",
    "            self.G = model_resnet.Resnet50_md(self.params.channel)\n",
    "        \n",
    "        else:\n",
    "            print ('not available model type')\n",
    "            return\n",
    "        \n",
    "        self.G.apply(self.weight_init)\n",
    "    \n",
    "    def set_cuda(self):\n",
    "        self.G = self.G.cuda()\n",
    "    \n",
    "    def weight_init(self, m):\n",
    "        classname = m.__class__.__name__\n",
    "        if classname.find('Conv') != -1:\n",
    "            m.weight.data.normal_(0.0, 0.02)\n",
    "        elif classname.find('BatchNorm2d') != -1:\n",
    "            m.weight.data.normal_(1.0, 0.02)\n",
    "            m.bias.data.fill_(0)\n",
    "    \n",
    "    def scale_pyramid(self, img, num_scales):\n",
    "        s = img.shape # expect BxCxHxW\n",
    "        h, w = s[2], s[3]\n",
    "        scaled_imgs = [img]\n",
    "        \n",
    "        for i in range(num_scales-1):\n",
    "            ratio = 2**(i+1)\n",
    "            nh = int(h // ratio)\n",
    "            nw = int(w // ratio)\n",
    "            img_up = functional.interpolate(img, size=(nh,nw), mode='nearest')\n",
    "            scaled_imgs.append(img_up)\n",
    "            \n",
    "        return scaled_imgs\n",
    "    \n",
    "    def generate_image_left(self, img, disp):\n",
    "        #return self.bilinear_sampler(img, -disp)\n",
    "        return self.apply_disparity(img, -disp)\n",
    "    \n",
    "    def generate_image_right(self, img, disp):\n",
    "        #return self.bilinear_sampler(img, disp)\n",
    "        return self.apply_disparity(img, disp)\n",
    "    \n",
    "    def gradient_x(self, img):\n",
    "        return img[:, :, :, :-1] - img[:, :, :, 1:]\n",
    "    \n",
    "    def gradient_y(self, img):\n",
    "        return img[:, :, :-1, :] - img[:, :, 1:, :]\n",
    "    \n",
    "    def get_disparity_smoothness(self, disp, pyramid):\n",
    "        disp_gradients_x = [self.gradient_x(d) for d in disp]\n",
    "        disp_gradients_y = [self.gradient_y(d) for d in disp]\n",
    "        \n",
    "        image_gradients_x = [self.gradient_x(img) for img in pyramid]\n",
    "        image_gradients_y = [self.gradient_y(img) for img in pyramid]\n",
    "        \n",
    "        weights_x = [torch.exp(-torch.mean(g.abs(), dim=1, keepdim=True)) for g in image_gradients_x]\n",
    "        weights_y = [torch.exp(-torch.mean(g.abs(), dim=1, keepdim=True)) for g in image_gradients_y]\n",
    "        \n",
    "        smoothness_x = [disp_gradients_x[i] * weights_x[i] for i in range(4)]\n",
    "        smoothness_y = [disp_gradients_y[i] * weights_y[i] for i in range(4)]\n",
    "        \n",
    "        return smoothness_x + smoothness_y\n",
    "        \n",
    "    def SSIM(self, x, y):\n",
    "        C1 = 0.01 ** 2\n",
    "        C2 = 0.03 ** 2\n",
    "        \n",
    "        AvgPool2d = nn.AvgPool2d(3, stride=1)\n",
    "        mu_x = AvgPool2d(x)\n",
    "        mu_y = AvgPool2d(y)\n",
    "        \n",
    "        sigma_x = AvgPool2d(x.pow(2)) - mu_x.pow(2)\n",
    "        sigma_y = AvgPool2d(y.pow(2)) - mu_y.pow(2)\n",
    "        sigma_xy = AvgPool2d(x*y) - mu_x * mu_y\n",
    "        \n",
    "        SSIM_n = (2*mu_x*mu_y + C1) * (2*sigma_xy+C2)\n",
    "        SSIM_d = (mu_x**2 + mu_y**2 + C1) * (sigma_x + sigma_y + C2)\n",
    "        SSIM = SSIM_n / SSIM_d\n",
    "        \n",
    "        return torch.clamp((1-SSIM)/2, 0, 1)\n",
    "    \n",
    "    def bilinear_sampler(self, images, x_offset, wrap_mode='border'):\n",
    "        \n",
    "        n_batch, n_channel, n_height, n_width = images.shape\n",
    "        \n",
    "        '''\n",
    "        x = torch.linspace(0, 1, n_width).cuda()\n",
    "        y = torch.linspace(0, 1, n_height).cuda()\n",
    "        \n",
    "        x = x.view(1, 1, -1).repeat(n_batch, n_height, 1)\n",
    "        y = y.view(1, -1, 1).repeat(n_batch, 1, n_width)\n",
    "        '''\n",
    "        \n",
    "        x = torch.linspace(0, 1, n_width).repeat(n_batch, n_height, 1).type_as(images)\n",
    "        y = torch.linspace(0, 1, n_height).repeat(n_batch, n_width, 1).transpose(1, 2).type_as(images)\n",
    "        \n",
    "        offset = x_offset[:, 0, :, :]\n",
    "        x = x + offset\n",
    "        \n",
    "        xy_grid = torch.stack((x,y), dim=3) # BxHxWx2\n",
    "        xy_grid = xy_grid * 2 - 1 # map range(0,1) to range(-1, 1)\n",
    "        images_generated = functional.grid_sample(images, xy_grid, padding_mode=wrap_mode)\n",
    "        \n",
    "        return images_generated\n",
    "        \n",
    "    def apply_disparity(self, input_images, x_offset, wrap_mode='border', tensor_type = 'torch.cuda.FloatTensor'):\n",
    "        num_batch, num_channels, height, width = input_images.size()\n",
    "\n",
    "        # Handle both texture border types\n",
    "        edge_size = 0\n",
    "        if wrap_mode == 'border':\n",
    "            edge_size = 1\n",
    "            # Pad last and second-to-last dimensions by 1 from both sides\n",
    "            input_images = functional.pad(input_images, (1, 1, 1, 1))\n",
    "        elif wrap_mode == 'edge':\n",
    "            edge_size = 0\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "        # Put channels to slowest dimension and flatten batch with respect to others\n",
    "        input_images = input_images.permute(1, 0, 2, 3).contiguous()\n",
    "        im_flat = input_images.view(num_channels, -1)\n",
    "\n",
    "        # Create meshgrid for pixel indicies (PyTorch doesn't have dedicated\n",
    "        # meshgrid function)\n",
    "        x = torch.linspace(0, width - 1, width).repeat(height, 1).type(tensor_type).cuda()\n",
    "        y = torch.linspace(0, height - 1, height).repeat(width, 1).transpose(0, 1).type(tensor_type).cuda()\n",
    "        # Take padding into account\n",
    "        x = x + edge_size\n",
    "        y = y + edge_size\n",
    "        # Flatten and repeat for each image in the batch\n",
    "        x = x.view(-1).repeat(1, num_batch)\n",
    "        y = y.view(-1).repeat(1, num_batch)\n",
    "\n",
    "        # Now we want to sample pixels with indicies shifted by disparity in X direction\n",
    "        # For that we convert disparity from % to pixels and add to X indicies\n",
    "        x = x + x_offset.contiguous().view(-1) * width\n",
    "        # Make sure we don't go outside of image\n",
    "        x = torch.clamp(x, 0.0, width - 1 + 2 * edge_size)\n",
    "        # Round disparity to sample from integer-valued pixel grid\n",
    "        y0 = torch.floor(y)\n",
    "        # In X direction round both down and up to apply linear interpolation\n",
    "        # between them later\n",
    "        x0 = torch.floor(x)\n",
    "        x1 = x0 + 1\n",
    "        # After rounding up we might go outside the image boundaries again\n",
    "        x1 = x1.clamp(max=(width - 1 + 2 * edge_size))\n",
    "\n",
    "        # Calculate indices to draw from flattened version of image batch\n",
    "        dim2 = (width + 2 * edge_size)\n",
    "        dim1 = (width + 2 * edge_size) * (height + 2 * edge_size)\n",
    "        # Set offsets for each image in the batch\n",
    "        base = dim1 * torch.arange(num_batch).type(tensor_type).cuda()\n",
    "        base = base.view(-1, 1).repeat(1, height * width).view(-1)\n",
    "        # One pixel shift in Y  direction equals dim2 shift in flattened array\n",
    "        base_y0 = base + y0 * dim2\n",
    "        # Add two versions of shifts in X direction separately\n",
    "        idx_l = base_y0 + x0\n",
    "        idx_r = base_y0 + x1\n",
    "\n",
    "        # Sample pixels from images\n",
    "        pix_l = im_flat.gather(1, idx_l.repeat(num_channels, 1).long())\n",
    "        pix_r = im_flat.gather(1, idx_r.repeat(num_channels, 1).long())\n",
    "\n",
    "        # Apply linear interpolation to account for fractional offsets\n",
    "        weight_l = x1 - x\n",
    "        weight_r = x - x0\n",
    "        output = weight_l * pix_l + weight_r * pix_r\n",
    "\n",
    "        # Reshape back into image batch and permute back to (N,C,H,W) shape\n",
    "        output = output.view(num_channels, num_batch, height, width).permute(1,0,2,3)\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def inference(self, test_input):\n",
    "        self.test_disp = self.G.forward(test_input)\n",
    "        return self.test_disp[0]\n",
    "    \n",
    "    def forward(self, left_image, right_image):\n",
    "\n",
    "        self.left_pyramid = self.scale_pyramid(left_image, 4)\n",
    "        if self.params.mode == 'train':\n",
    "            self.right_pyramid = self.scale_pyramid(right_image, 4)\n",
    "        \n",
    "        # skip the stereo training part\n",
    "\n",
    "        model_input = left_image\n",
    "        \n",
    "        self.disp_est = self.G.forward(model_input)\n",
    "        self.disp_left_est = [torch.unsqueeze(d[:, 0, :, :], 1) for d in self.disp_est]\n",
    "        self.disp_right_est = [torch.unsqueeze(d[:, 1, :, :], 1) for d in self.disp_est]\n",
    "        \n",
    "        if self.params.mode == 'test' or self.params.mode == 'evaluate': # Loss information is not needed in testing\n",
    "            return\n",
    "        \n",
    "        # generate images\n",
    "        self.left_est = [ self.generate_image_left(self.right_pyramid[i], self.disp_left_est[i]) for i in range(4)]\n",
    "        self.right_est = [ self.generate_image_right(self.left_pyramid[i], self.disp_right_est[i]) for i in range(4)]\n",
    "        \n",
    "        # LR consistency\n",
    "        self.right_to_left_disp = [self.generate_image_left(self.disp_right_est[i], self.disp_left_est[i]) for i in range(4)]\n",
    "        self.left_to_right_disp = [self.generate_image_right(self.disp_left_est[i], self.disp_right_est[i]) for i in range(4)]\n",
    "        \n",
    "        # disparity smoothness\n",
    "        self.disp_left_smoothness = self.get_disparity_smoothness(self.disp_left_est, self.left_pyramid)\n",
    "        self.disp_right_smoothness = self.get_disparity_smoothness(self.disp_right_est, self.right_pyramid)\n",
    "        \n",
    "        self.build_loss()\n",
    "        return self.total_loss.item()\n",
    "        \n",
    "    def build_loss(self):\n",
    "        # L1\n",
    "        self.l1_left = [torch.abs(self.left_est[i] - self.left_pyramid[i]) for i in range(4)]\n",
    "        self.l1_reconstruct_loss_left = [torch.mean(l) for l in self.l1_left]\n",
    "        self.l1_right = [torch.abs(self.right_est[i] - self.right_pyramid[i]) for i in range(4)]\n",
    "        self.l1_reconstruct_loss_right = [torch.mean(l) for l in self.l1_right]\n",
    "        \n",
    "        # SSIM\n",
    "        self.ssim_left = [self.SSIM(self.left_est[i], self.left_pyramid[i]) for i in range(4)]\n",
    "        self.ssim_loss_left = [torch.mean(l) for l in self.ssim_left]\n",
    "        self.ssim_right = [self.SSIM(self.right_est[i], self.right_pyramid[i]) for i in range(4)]\n",
    "        self.ssim_loss_right = [torch.mean(l) for l in self.ssim_right]\n",
    "        \n",
    "        # weighted sum\n",
    "        self.image_loss_left = [self.params.alpha * self.ssim_loss_left[i] + (1-self.params.alpha)*(self.l1_reconstruct_loss_left[i]) for i in range(4)]\n",
    "        self.image_loss_right = [self.params.alpha * self.ssim_loss_right[i] + (1-self.params.alpha)*(self.l1_reconstruct_loss_right[i]) for i in range(4)]\n",
    "        self.image_loss = sum(self.image_loss_left + self.image_loss_right)\n",
    "        \n",
    "        # disparity smoothness\n",
    "        self.disp_left_loss = [torch.mean(torch.abs(self.disp_left_smoothness[i])) / 2**i for i in range(4)]\n",
    "        self.disp_right_loss = [torch.mean(torch.abs(self.disp_right_smoothness[i])) / 2**i for i in range(4)]\n",
    "        self.disp_gradient_loss = sum(self.disp_left_loss + self.disp_right_loss)\n",
    "        \n",
    "        # LR consistency\n",
    "        self.lr_left_loss = [torch.mean(torch.abs(self.right_to_left_disp[i] - self.disp_left_est[i])) for i in range(4)]\n",
    "        self.lr_right_loss = [torch.mean(torch.abs(self.left_to_right_disp[i] - self.disp_right_est[i])) for i in range(4)]\n",
    "        self.lr_loss = sum(self.lr_left_loss + self.lr_right_loss)\n",
    "        \n",
    "        # total\n",
    "        self.total_loss = (\n",
    "                            self.image_loss + \n",
    "                            self.params.disp_gradient_loss_weight * self.disp_gradient_loss + \n",
    "                            self.params.lr_loss_weight * self.lr_loss )\n",
    "        \n",
    "    def display_image(self, path, epoch):\n",
    "        '''\n",
    "            left-image input, right-image input\n",
    "            left-image est, right-image est\n",
    "            left disp, right disp\n",
    "        '''\n",
    "        if not os.path.exists(path):\n",
    "                os.makedirs(path)\n",
    "        \n",
    "        to_pil = transforms.Compose([transforms.ToPILImage()])\n",
    "        \n",
    "        for i in range(self.params.batch_size):\n",
    "            plt.figure()\n",
    "            \n",
    "            plt.subplot(3,2,1)\n",
    "            plt.imshow(np.asarray(to_pil(self.left_pyramid[0][i].cpu())))\n",
    "            plt.title('left image input')\n",
    "            plt.axis('off')\n",
    "            \n",
    "            plt.subplot(3,2,2)\n",
    "            plt.imshow(np.asarray(to_pil(self.right_pyramid[0][i].cpu())))\n",
    "            plt.title('right image input')\n",
    "            plt.axis('off')\n",
    "            \n",
    "            plt.subplot(3,2,3)\n",
    "            plt.imshow(np.asarray(to_pil(self.left_est[0][i].cpu())))\n",
    "            plt.title('left image output')\n",
    "            plt.axis('off')\n",
    "            \n",
    "            plt.subplot(3,2,4)\n",
    "            plt.imshow(np.asarray(to_pil(self.right_est[0][i].cpu())))\n",
    "            plt.title('right image output')\n",
    "            plt.axis('off')\n",
    "            \n",
    "            plt.subplot(3,2,5)\n",
    "            disp_image_left = self.disp_left_est[0][i].cpu().data.numpy()\n",
    "            plt.imshow(disp_image_left.squeeze(), cmap=plt.get_cmap('plasma'))\n",
    "            plt.title('left disparity estimation')\n",
    "            plt.axis('off')\n",
    "            \n",
    "            plt.subplot(3,2,6)\n",
    "            disp_image_right = self.disp_right_est[0][i].cpu().data.numpy()\n",
    "            plt.imshow(disp_image_right.squeeze(), cmap=plt.get_cmap('plasma'))\n",
    "            plt.title('right disparity estimation')\n",
    "            plt.axis('off')\n",
    "            \n",
    "            plt.savefig('{}/img{:02d}-epoch{:02d}.jpg'.format(path, i+1, epoch), dpi=100)\n",
    "            plt.close()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
